{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioCypher Tutorial - Basics with Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of BioCypher is to facilitate the pre-processing of biomedical data, and thus save development time in the maintenance of curated knowledge graphs, while allowing simple and efficient creation of task-specific lightweight knowledge graphs in a user-friendly and biology-centric fashion.\n",
    "\n",
    "We are going to use a toy example to familiarise the user with the basic functionality of BioCypher. One central task of BioCypher is the harmonisation of dissimilar datasets describing the same entities. Thus, in this example, the input data - which in the real-world use case could come from any type of interface - are represented by simulated data containing some examples of differently formatted biomedical entities such as proteins and their interactions.\n",
    "\n",
    "There are two other versions of this tutorial, which only differ in the output format. The first uses a CSV output format to write files suitable for Neo4j admin import, and the second creates an in-memory collection of Pandas dataframes. You can find both in the tutorial directory of the BioCypher repository. This tutorial simply takes the in-memory approach to a Jupyter notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While BioCypher was designed as a graph-focused framework, due to commonalities in bioinformatics workflows, BioCypher also supports Pandas DataFrames. This allows integration with methods that use tabular data, such as machine learning and statistical analysis, for instance in the [scVerse framework](https://scverse.org)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this tutorial, you will need to have cloned and installed the BioCypher repository on your machine. We recommend using [Poetry](https://python-poetry.org/). \n",
    "\n",
    "To obtain both, run the following commands in your terminal:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bash}\n",
    "git clone https://github.com/biocypher/biocypher.git\n",
    "cd biocypher\n",
    "poetry install\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<h5> Poetry environment </h5>\n",
    "\n",
    "In order to run the tutorial code, you will need to activate the Poetry\n",
    "environment. This can be done by running `poetry shell` in the `biocypher`\n",
    "directory. Alternatively, you can run the code from within the Poetry\n",
    "environment by prepending `poetry run` to the command. For example, to run the\n",
    "tutorial code, you can run `poetry run python tutorial/01__basic_import.py`.\n",
    "\n",
    "\n",
    "</div>  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `biocypher` root directory, you will find a `tutorial` directory with\n",
    "the files for this tutorial. The `data_generator.py` file contains the\n",
    "simulated data generation code, and the other files are named according to the\n",
    "tutorial step they are used in. The `biocypher-out` directory will be created\n",
    "automatically when you run the tutorial code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "  <strong> @slobentanzer wouldn't it be easier to just have the data_generator under biocypher.test - to avoid cloning the whole repo for the tutorials?\n",
    "This file would also then fit in docs (depending how you want to refer to it for the read the docs) </strong>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to print yaml files\n",
    "import yaml\n",
    "def print_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        yaml_data = yaml.safe_load(file)\n",
    "\n",
    "    print(\"--------------\")\n",
    "    print(yaml.dump(yaml_data, sort_keys=False, indent=4))\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "BioCypher is configured using a YAML file; it comes with a default (which you\n",
    "can see in the [Configuration](config) section). You can use it, for instance,\n",
    "to select an output format, the output directory, separators, logging level, and\n",
    "other options. For this tutorial, we will use a dedicated configuration file for\n",
    "each of the steps. The configuration files are located in the `tutorial`\n",
    "directory, and are called using the `biocypher_config_path` argument at\n",
    "instantiation of the BioCypher interface. For more information, see also the\n",
    "[Quickstart Configuration](quick_config) section.\n",
    "\n",
    "## Section 1: Adding data\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<h5> Tutorial files </h5>\n",
    "\n",
    "The code for this tutorial can be found at `tutorial/01__basic_import.py`. The\n",
    "schema is at `tutorial/01_schema_config.yaml`, configuration in\n",
    "`tutorial/01_biocypher_config.yaml`. Data generation happens in\n",
    "`tutorial/data_generator.py`.\n",
    "\n",
    "</div>  \n",
    "\n",
    "### Input data stream (\"adapter\")\n",
    "The basic operation of adding data to the knowledge graph requires two\n",
    "components: an input stream of data (which we call adapter) and a configuration\n",
    "for the resulting desired output (the schema configuration). The former will be\n",
    "simulated by calling the `Protein` class of our data generator 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of proteins to be imported\n",
    "from data_generator import Protein\n",
    "n_proteins = 3\n",
    "proteins = [Protein() for _ in range(n_proteins)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each protein in our simulated data has a UniProt ID, a label\n",
    "(\"uniprot_protein\"), and a dictionary of properties describing it. This is -\n",
    "purely by coincidence - very close to the input BioCypher expects (for nodes):\n",
    "- a unique identifier\n",
    "- an input label (to allow mapping to the ontology, see the second step below)\n",
    "- a dictionary of further properties (which can be empty)\n",
    "\n",
    "These should be presented to BioCypher in the form of a tuple. To achieve this\n",
    "representation, we can use a generator function that iterates through our\n",
    "simulated input data and, for each entity, forms the corresponding tuple. The\n",
    "use of a generator allows for efficient streaming of larger datasets where\n",
    "required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_generator(proteins):\n",
    "    for protein in proteins:\n",
    "        yield (\n",
    "            protein.get_id(),\n",
    "            protein.get_label(),\n",
    "            protein.get_properties(),\n",
    "        )\n",
    "entities = node_generator(proteins)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of an adapter can become arbitrarily complex and involve\n",
    "programmatic access to databases, API requests, asynchronous queries, context\n",
    "managers, and other complicating factors. However, it always boils down to\n",
    "providing the BioCypher driver with a collection of tuples, one for each entity\n",
    "in the input data. For more info, see the section on\n",
    "[Adapters](adapter_functions).\n",
    "\n",
    "As descibed above, *nodes* possess:\n",
    "\n",
    "- a mandatory ID,\n",
    "- a mandatory label, and\n",
    "- a property dictionary,\n",
    "\n",
    "while *edges* possess:\n",
    "\n",
    "- an (optional) ID,\n",
    "- two mandatory IDs for source and target,\n",
    "- a mandatory label, and\n",
    "- a property dictionary.\n",
    "\n",
    "How these entities are mapped to the ontological hierarchy underlying a\n",
    "BioCypher graph is determined by their mandatory labels, which connect the input\n",
    "data stream to the schema configuration. This we will see in the following\n",
    "section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema configuration\n",
    "How each BioCypher graph is structured is determined by the schema configuration\n",
    "YAML file that is given to the BioCypher interface. This also serves to ground\n",
    "the entities of the graph in the biomedical realm by using an ontological\n",
    "hierarchy. In this tutorial, we refer to the Biolink model as the general\n",
    "backbone of our ontological hierarchy. The basic premise of the schema\n",
    "configuration YAML file is that each component of the desired knowledge graph\n",
    "output should be configured here; if (and only if) an entity is represented in\n",
    "the schema configuration *and* is present in the input data stream, will it be\n",
    "part of our knowledge graph.\n",
    "\n",
    "In our case, since we only import proteins, we only require few lines of\n",
    "configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -- This is BioCypher v0.5.15.\n",
      "INFO -- Logging into `biocypher-log/biocypher-20230531-143205.log`.\n"
     ]
    }
   ],
   "source": [
    "from biocypher import BioCypher\n",
    "from os.path import join\n",
    "schema_path = join('..', 'tutorial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "protein:\n",
      "    represented_as: node\n",
      "    preferred_id: uniprot\n",
      "    input_label: uniprot_protein\n",
      "\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "print_yaml(join(schema_path, '01_schema_config.yaml'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line (`protein`) identifies our entity and connects to the\n",
    "ontological backbone; here we define the first class to be represented in the\n",
    "graph. In the configuration YAML, we represent entities — similar to the\n",
    "internal representation of Biolink — in lower sentence case (e.g., \"small\n",
    "molecule\"). Conversely, for class names, in file names, and property graph\n",
    "labels, we use PascalCase instead (e.g., \"SmallMolecule\") to avoid issues with\n",
    "handling spaces. The transformation is done by BioCypher internally. BioCypher\n",
    "does not strictly enforce the entities allowed in this class definition; in\n",
    "fact, we provide [several methods of extending the existing ontological\n",
    "backbone *ad hoc* by providing custom inheritance or hybridising\n",
    "ontologies](biolink). However, every entity should at some point be connected\n",
    "to the underlying ontology, otherwise the multiple hierarchical labels will not\n",
    "be populated. Following this first line are three indented values of the\n",
    "protein class.\n",
    "\n",
    "The second line (`represented_as`) tells BioCypher in which way each entity\n",
    "should be represented in the graph; the only options are `node` and `edge`.\n",
    "Representation as an edge is only possible when source and target IDs are\n",
    "provided in the input data stream. Conversely, relationships can be represented\n",
    "as both `node` or `edge`, depending on the desired output. When a relationship\n",
    "should be represented as a node, i.e., \"reified\", BioCypher takes care to create\n",
    "a set of two edges and a node in place of the relationship. This is useful when\n",
    "we want to connect the relationship to other entities in the graph, for example\n",
    "literature references.\n",
    "\n",
    "The third line (`preferred_id`) informs the uniqueness of represented entities\n",
    "by selecting an ontological namespace around which the definition of uniqueness\n",
    "should revolve. In our example, if a protein has its own uniprot ID, it is\n",
    "understood to be a unique entity. When there are multiple protein isoforms\n",
    "carrying the same uniprot ID, they are understood to be aggregated to result in\n",
    "only one unique entity in the graph. Decisions around uniqueness of graph\n",
    "constituents sometimes require some consideration in task-specific\n",
    "applications. Selection of a namespace also has effects in identifier mapping;\n",
    "in our case, for protein nodes that do not carry a uniprot ID, identifier\n",
    "mapping will attempt to find a uniprot ID given the other identifiers of that\n",
    "node. To account for the broadest possible range of identifier systems while\n",
    "also dealing with parsing of namespace prefixes and validation, we refer to the\n",
    "[Bioregistry](https://bioregistry.io) project namespaces, which should be\n",
    "preferred values for this field.\n",
    "\n",
    "Finally, the fourth line (`input_label`) connects the input data stream to the\n",
    "configuration; here we indicate which label to expect in the input tuple for\n",
    "each class in the graph. In our case, we expect \"uniprot_protein\" as the label\n",
    "for each protein in the input data stream; all other input entities that do not\n",
    "carry this label are ignored as long as they are not in the schema\n",
    "configuration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the graph (using the BioCypher interface)\n",
    "All that remains to be done now is to instantiate the BioCypher interface (as the\n",
    "main means of communicating with BioCypher) and call the function to create the\n",
    "graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -- Loading ontologies...\n",
      "INFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n"
     ]
    }
   ],
   "source": [
    "bc = BioCypher(\n",
    "    biocypher_config_path=join(schema_path, '01_biocypher_config.yaml'),\n",
    "    schema_config_path=join(schema_path, '01_schema_config.yaml'),\n",
    ")\n",
    "# Add the entities that we generated above to the graph\n",
    "bc.add(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'protein':   node_id node_label                                           sequence   \n",
       " 0  B9H6B4    protein  WIPLVMQNEATFYLDRRHSYMIVRVNDGFWPTFNFVHADYDMIWVM...  \\\n",
       " 1  F2T4J1    protein  DFDNHIQDLMLHHSMRRISEPHFELVKSNINLGLLQHPPGWFEYEC...   \n",
       " 2  G6B5W0    protein  LTIYDIIFFEWPHCMEQVHYQLSTWLKIQIPQVWRCAYQWDPANFR...   \n",
       " \n",
       "            description taxon      id preferred_id  \n",
       " 0  f f o r u x r n l u  9606  B9H6B4      uniprot  \n",
       " 1  t o z u t s f s p u  9606  F2T4J1      uniprot  \n",
       " 2  e r s w h w x h i l  9606  G6B5W0      uniprot  }"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the graph as a dictionary of pandas DataFrame(s) per node label\n",
    "bc.to_df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Merging data\n",
    "\n",
    "### Plain merge\n",
    "\n",
    "Using the workflow described above with minor changes, we can merge data from\n",
    "different input streams. If we do not want to introduce additional ontological\n",
    "subcategories, we can simply add the new input stream to the existing one and\n",
    "add the new label to the schema configuration (the new label being\n",
    "`entrez_protein`). In this case, we would add the following to the schema\n",
    "configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import Protein, EntrezProtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "protein:\n",
      "    represented_as: node\n",
      "    preferred_id: uniprot\n",
      "    input_label:\n",
      "    - uniprot_protein\n",
      "    - entrez_protein\n",
      "\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "print_yaml(join(schema_path, '02_schema_config.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -- Loading ontologies...\n",
      "INFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n"
     ]
    }
   ],
   "source": [
    "# Create a list of proteins to be imported\n",
    "proteins = [\n",
    "    p for sublist in zip(\n",
    "        [Protein() for _ in range(n_proteins)],\n",
    "        [EntrezProtein() for _ in range(n_proteins)],\n",
    "    ) for p in sublist\n",
    "]\n",
    "# Create a new BioCypher instance\n",
    "bc = BioCypher(\n",
    "    biocypher_config_path=join(schema_path, '02_biocypher_config.yaml'),\n",
    "    schema_config_path=join(schema_path, '02_schema_config.yaml'),\n",
    ")\n",
    "# Run the import\n",
    "bc.add(node_generator(proteins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'protein':   node_id node_label                                           sequence   \n",
       " 0  I3F2Z9    protein  REHLAWIVSPQCFRERSMCNTYCHHSHLLLRTKPMVDIVEPMACCG...  \\\n",
       " 1  190794    protein  REPMQAKWMPGYFAYRITILLKSNQMVWSVYMPMHAKWSHEHWLWS...   \n",
       " 2  G6M3X6    protein  EICYKSPTYFMMRASTAPWAAVDCEEATEGNRWHVPDLGNPGDIGH...   \n",
       " 3  834464    protein  WCNRTALLTHSGSAYGENCKFQAHKRTRETGKGTHDLIWDRYDYEF...   \n",
       " 4  E0L5X8    protein  VFFLFGTTMSVCPCDELQMPICDSVIADIFNMCSDEQFQWPWEEQI...   \n",
       " 5  360805    protein  QRMHIYDLGNIDMPGPCKCMVKDWPSGIDCKNFGTQFHVVKPGEII...   \n",
       " \n",
       "            description taxon      id preferred_id  \n",
       " 0  v l q z t h w q c x  9606  I3F2Z9      uniprot  \n",
       " 1  t m f w e z q r m l  9606  190794      uniprot  \n",
       " 2  h q p i z u a w o t  9606  G6M3X6      uniprot  \n",
       " 3  h g k u m p p i v b  9606  834464      uniprot  \n",
       " 4  q l u d k s q p v l  9606  E0L5X8      uniprot  \n",
       " 5  y i j o l b a c m f  9606  360805      uniprot  }"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.to_df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This again creates a single DataFrame, now for both protein types, but now including\n",
    "both input streams (you should note both uniprot & entrez style IDs in the id column). However, we are generating our `entrez`\n",
    "proteins as having entrez IDs, which could result in problems in querying.\n",
    "Additionally, a strict import mode including regex pattern matching of\n",
    "identifiers will fail at this point due to the difference in pattern of UniProt\n",
    "vs. Entrez IDs. This issue could be resolved by mapping the Entrez IDs to\n",
    "UniProt IDs, but we will instead use the opportunity to demonstrate how to\n",
    "merge data from different sources into the same ontological class using *ad\n",
    "hoc* subclasses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Ad hoc* subclassing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we saw how to merge data from different sources into\n",
    "the same ontological class. However, we did not resolve the issue of the\n",
    "`entrez` proteins living in a different namespace than the `uniprot` proteins,\n",
    "which could result in problems in querying. In proteins, it would probably be\n",
    "more appropriate to solve this problem using identifier mapping, but in other\n",
    "categories, e.g., pathways, this may not be possible because of a lack of\n",
    "one-to-one mapping between different data sources. Thus, if we so desire, we\n",
    "can merge datasets into the same ontological class by creating *ad hoc*\n",
    "subclasses implicitly through BioCypher, by providing multiple preferred\n",
    "identifiers. In our case, we update our schema configuration as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "protein:\n",
      "    represented_as: node\n",
      "    preferred_id:\n",
      "    - uniprot\n",
      "    - entrez\n",
      "    input_label:\n",
      "    - uniprot_protein\n",
      "    - entrez_protein\n",
      "\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "print_yaml(join(schema_path, '03_schema_config.yaml'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will \"implicitly\" create two subclasses of the `protein` class, which will\n",
    "inherit the entire hierarchy of the `protein` class. The two subclasses will be\n",
    "named using a combination of their preferred namespace and the name of the\n",
    "parent class, separated by a dot, i.e., `uniprot.protein` and `entrez.protein`.\n",
    "In this manner, they can be identified as proteins regardless of their sources\n",
    "by any queries for the generic `protein` class, while still carrying\n",
    "information about their namespace and avoiding identifier conflicts.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "The only change affected upon the code from the previous section is the\n",
    "referral to the updated schema configuration file.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "In the output, we now generate two separate files for the `protein` class, one\n",
    "for each subclass (with names in PascalCase).\n",
    "</div>\n",
    "\n",
    "Let's create a DataFrame with the same nodes as above, but with a different schema configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -- Loading ontologies...\n",
      "INFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'uniprot.protein':   node_id       node_label                                           sequence   \n",
       " 0  I3F2Z9  uniprot.protein  REHLAWIVSPQCFRERSMCNTYCHHSHLLLRTKPMVDIVEPMACCG...  \\\n",
       " 1  G6M3X6  uniprot.protein  EICYKSPTYFMMRASTAPWAAVDCEEATEGNRWHVPDLGNPGDIGH...   \n",
       " 2  E0L5X8  uniprot.protein  VFFLFGTTMSVCPCDELQMPICDSVIADIFNMCSDEQFQWPWEEQI...   \n",
       " \n",
       "            description taxon      id preferred_id  \n",
       " 0  v l q z t h w q c x  9606  I3F2Z9      uniprot  \n",
       " 1  h q p i z u a w o t  9606  G6M3X6      uniprot  \n",
       " 2  q l u d k s q p v l  9606  E0L5X8      uniprot  ,\n",
       " 'entrez.protein':   node_id      node_label                                           sequence   \n",
       " 0  190794  entrez.protein  REPMQAKWMPGYFAYRITILLKSNQMVWSVYMPMHAKWSHEHWLWS...  \\\n",
       " 1  834464  entrez.protein  WCNRTALLTHSGSAYGENCKFQAHKRTRETGKGTHDLIWDRYDYEF...   \n",
       " 2  360805  entrez.protein  QRMHIYDLGNIDMPGPCKCMVKDWPSGIDCKNFGTQFHVVKPGEII...   \n",
       " \n",
       "            description taxon      id preferred_id  \n",
       " 0  t m f w e z q r m l  9606  190794       entrez  \n",
       " 1  h g k u m p p i v b  9606  834464       entrez  \n",
       " 2  y i j o l b a c m f  9606  360805       entrez  }"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc = BioCypher(\n",
    "    biocypher_config_path=join(schema_path, '03_biocypher_config.yaml'),\n",
    "    schema_config_path=join(schema_path, '03_schema_config.yaml'),\n",
    ")\n",
    "bc.add(node_generator(proteins))\n",
    "bc.to_df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see two separate DataFrames, one for each subclass of the `protein` class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Handling properties\n",
    "While ID and label are mandatory components of our knowledge graph, properties\n",
    "are optional and can include different types of information on the entities. In\n",
    "source data, properties are represented in arbitrary ways, and designations\n",
    "rarely overlap even for the most trivial of cases (spelling differences,\n",
    "formatting, etc). Additionally, some data sources contain a large wealth of\n",
    "information about entities, most of which may not be needed for the given task.\n",
    "Thus, it is often desirable to filter out properties that are not needed to\n",
    "save time, disk space, and memory.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Maintaining consistent properties per entity type is particularly important\n",
    "when using the admin import feature of Neo4j, which requires consistency\n",
    "between the header and data files. Properties that are introduced into only\n",
    "some of the rows will lead to column misalignment and import failure. In\n",
    "\"online mode\", this is not an issue.\n",
    "\n",
    "</div>\n",
    "\n",
    "We will take a look at how to handle property selection in BioCypher in a\n",
    "way that is flexible and easy to maintain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designated properties\n",
    "\n",
    "The simplest and most straightforward way to ensure that properties are\n",
    "consistent for each entity type is to designate them explicitly in the schema\n",
    "configuration. This is done by adding a `properties` key to the entity type\n",
    "configuration. The value of this key is another dictionary, where in the\n",
    "standard case the keys are the names of the properties that the entity type\n",
    "should possess, and the values give the type of the property. Possible values\n",
    "are:\n",
    "\n",
    "- `str` (or `string`),\n",
    "\n",
    "- `int` (or `integer`, `long`),\n",
    "\n",
    "- `float` (or `double`, `dbl`),\n",
    "\n",
    "- `bool` (or `boolean`),\n",
    "\n",
    "- arrays of any of these types (indicated by square brackets, e.g. `string[]`).\n",
    "\n",
    "In the case of properties that are not present in (some of) the source data,\n",
    "BioCypher will add them to the output with a default value of `None`.\n",
    "Additional properties in the input that are not represented in these designated\n",
    "property names will be ignored. Let's imagine that some, but not all, of our\n",
    "protein nodes have a `mass` value. If we want to include the mass value on all\n",
    "proteins, we can add the following to our schema configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "protein:\n",
      "    represented_as: node\n",
      "    preferred_id:\n",
      "    - uniprot\n",
      "    - entrez\n",
      "    input_label:\n",
      "    - uniprot_protein\n",
      "    - entrez_protein\n",
      "    properties:\n",
      "        sequence: str\n",
      "        description: str\n",
      "        taxon: str\n",
      "        mass: int\n",
      "\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "print_yaml(join(schema_path, '04_schema_config.yaml'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will add the `mass` property to all proteins (in addition to the three we\n",
    "had before); if not encountered, the column will be empty. Implicit subclasses\n",
    "will automatically inherit the property configuration; in this case, both\n",
    "`uniprot.protein` and `entrez.protein` will have the `mass` property, even\n",
    "though the `entrez` proteins do not have a `mass` value in the input data.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "If we wanted to ignore the mass value for all properties, we could simply\n",
    "remove the `mass` key from the `properties` dictionary.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import EntrezProtein, RandomPropertyProtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -- Loading ontologies...\n",
      "INFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'uniprot.protein':   node_id       node_label                                           sequence   \n",
       " 0  T4G5C9  uniprot.protein  LQKEYAALFWQPRAFYPYLIKSFLDEAKRDCFWMMIFPVKSWWHHQ...  \\\n",
       " 1  W5O6Z3  uniprot.protein  SNNQCAIATWAVSFWMSSGAFSLLSMDFCTHENHFGVTRFGDWKEH...   \n",
       " 2  U5W6F4  uniprot.protein  SYKECEYWEKSGNIFNTMREREWNFCKKLKMQIFKCIWWLNGNKWI...   \n",
       " \n",
       "            description taxon    mass      id preferred_id  \n",
       " 0  f m l t b y w t b i  9138  7018.0  T4G5C9      uniprot  \n",
       " 1  a p d z o i w u g r  4555  3025.0  W5O6Z3      uniprot  \n",
       " 2  m g r l w m d d g a  6432     NaN  U5W6F4      uniprot  ,\n",
       " 'entrez.protein':   node_id      node_label                                           sequence   \n",
       " 0   75149  entrez.protein  LSCQTWVPFKQPIFNICHIASAPENQQHGCVVGTHPMDKSRTHLEI...  \\\n",
       " 1  376243  entrez.protein  FSMMCWDLQHWDCRAQRCWKEKKIDSIDSVKRCQFLCDLIREEIPT...   \n",
       " 2  120953  entrez.protein  TALWMVIRSYFQACYTWHYIRFRNWVFGSWYRMEHIDDDMKFCKEA...   \n",
       " \n",
       "            description taxon  mass      id preferred_id  \n",
       " 0  i y y t o u i c o w  9606  None   75149       entrez  \n",
       " 1  j g g g u s c k f n  9606  None  376243       entrez  \n",
       " 2  g g s k j f r i f c  9606  None  120953       entrez  }"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of proteins to be imported (now with properties)\n",
    "proteins = [\n",
    "    p for sublist in zip(\n",
    "        [RandomPropertyProtein() for _ in range(n_proteins)],\n",
    "        [EntrezProtein() for _ in range(n_proteins)],\n",
    "    ) for p in sublist\n",
    "]\n",
    "# New instance, populated, and to DataFrame\n",
    "bc = BioCypher(\n",
    "    biocypher_config_path=join(schema_path, '04_biocypher_config.yaml'),\n",
    "    schema_config_path=join(schema_path, '04_schema_config.yaml'),\n",
    ")\n",
    "bc.add(node_generator(proteins))\n",
    "bc.to_df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inheriting properties\n",
    "Sometimes, explicit designation of properties requires a lot of maintenance\n",
    "work, particularly for classes with many properties. In these cases, it may be\n",
    "more convenient to inherit properties from a parent class. This is done by\n",
    "adding a `properties` key to a suitable parent class configuration, and then\n",
    "defining inheritance via the `is_a` key in the child class configuration and\n",
    "setting the `inherit_properties` key to `true`.\n",
    "\n",
    "Let's say we have an additional `protein isoform` class, which can reasonably\n",
    "inherit from `protein` and should carry the same properties as the parent. We\n",
    "can add the following to our schema configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import RandomPropertyProteinIsoform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "protein:\n",
      "    represented_as: node\n",
      "    preferred_id:\n",
      "    - uniprot\n",
      "    - entrez\n",
      "    input_label:\n",
      "    - uniprot_protein\n",
      "    - entrez_protein\n",
      "    properties:\n",
      "        sequence: str\n",
      "        description: str\n",
      "        taxon: str\n",
      "        mass: int\n",
      "protein isoform:\n",
      "    is_a: protein\n",
      "    inherit_properties: true\n",
      "    represented_as: node\n",
      "    preferred_id: uniprot\n",
      "    input_label: uniprot_isoform\n",
      "\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "print_yaml(join(schema_path, '05_schema_config.yaml'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows maintenance of property lists for many classes at once. If the child\n",
    "class has properties already, they will be kept (if they are not present in the\n",
    "parent class) or replaced by the parent class properties (if they are present).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Again, apart from adding the protein isoforms to the input stream, the code\n",
    "for this example is identical to the previous one except for the reference to\n",
    "the updated schema configuration.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "We now create three separate DataFrames, all of which are children of the\n",
    "`protein` class; two implicit children (`uniprot.protein` and `entrez.protein`)\n",
    "and one explicit child (`protein isoform`).\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -- Loading ontologies...\n",
      "INFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniprot.protein\n",
      "  node_id       node_label                                           sequence   \n",
      "0  U5Z5S0  uniprot.protein  PLWSVAKIHAEELPLLEYFVPDGSYDVPRGKMVNEFSEPEHWNVQC...  \\\n",
      "1  B1B6J7  uniprot.protein  VMYTFYDDGQHYHMWIGADYLLMVNNQDEPEEGINWWKLPLTNQVN...   \n",
      "2  R9B8P2  uniprot.protein  WQACQITEDLRKNYQNADRWTSQFALEPTAVQNCYRLLQPQLTQMD...   \n",
      "\n",
      "           description taxon    mass      id preferred_id  \n",
      "0  y n d f b v j i d t  8076     NaN  U5Z5S0      uniprot  \n",
      "1  r j j d c g l b z z  9741     NaN  B1B6J7      uniprot  \n",
      "2  a h u h p w b x d z  7295  3887.0  R9B8P2      uniprot  \n",
      "protein isoform\n",
      "  node_id       node_label                                           sequence   \n",
      "0  H0D1M0  protein isoform  YCETYMKVVMRQYIHREESYRHEPGAKLCDTMWQIPDILPSWYEQF...  \\\n",
      "1  X8N1C4  protein isoform  MMPIREQSGVQCWCTWKQKSTWSKIANEGRFDHYWGYRRWYVFYMS...   \n",
      "2  Q3I2X0  protein isoform  MEPYKREGAQPAPASGVASSIWQFSNHMCVDMKGTRIQCKNTRCLA...   \n",
      "\n",
      "           description taxon    mass      id preferred_id  \n",
      "0  f m a c f l u r a d  4278     NaN  H0D1M0      uniprot  \n",
      "1  c z v l z q r z q i  4830     NaN  X8N1C4      uniprot  \n",
      "2  s m l i n n k f k x  1925  7594.0  Q3I2X0      uniprot  \n",
      "entrez.protein\n",
      "  node_id      node_label                                           sequence   \n",
      "0  503804  entrez.protein  NLNTNVYSPEPYAQKYLMDCQLVIHNLPYHLCNSPSSLVYADIFQW...  \\\n",
      "1  103919  entrez.protein  YPHSFIFYCVSKCWWMKELMMKTLYQTTRCCRTGLQCLSQWDPFMM...   \n",
      "2  170557  entrez.protein  RTCYFANEPITMCHPNWQWHHTCKADNAIGKNDMWTCIGYLAPDTW...   \n",
      "\n",
      "           description taxon  mass      id preferred_id  \n",
      "0  p w z n p o x u v l  9606  None  503804       entrez  \n",
      "1  a p o j l y j w n n  9606  None  103919       entrez  \n",
      "2  g m s x m q q z i j  9606  None  170557       entrez  \n"
     ]
    }
   ],
   "source": [
    "# create a list of proteins to be imported\n",
    "proteins = [\n",
    "    p for sublist in zip(\n",
    "        [RandomPropertyProtein() for _ in range(n_proteins)],\n",
    "        [RandomPropertyProteinIsoform() for _ in range(n_proteins)],\n",
    "        [EntrezProtein() for _ in range(n_proteins)],\n",
    "    ) for p in sublist\n",
    "]\n",
    "\n",
    "# Create BioCypher driver\n",
    "bc = BioCypher(\n",
    "    biocypher_config_path=join(schema_path, '05_biocypher_config.yaml'),\n",
    "    schema_config_path=join(schema_path, '05_schema_config.yaml'),\n",
    ")\n",
    "# Run the import\n",
    "bc.add(node_generator(proteins))\n",
    "\n",
    "for name, df in bc.to_df().items():\n",
    "    print(name)\n",
    "    print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Handling relationships\n",
    "\n",
    "Naturally, we do not only want nodes in our knowledge graph, but also edges. In\n",
    "BioCypher, the configuration of relationships is very similar to that of nodes,\n",
    "with some key differences. First the similarities: the top-level class\n",
    "configuration of edges is the same; class names refer to ontological classes or\n",
    "are an extension thereof. Similarly, the `is_a` key is used to define\n",
    "inheritance, and the `inherit_properties` key is used to inherit properties from\n",
    "a parent class. Relationships also possess a `preferred_id` key, an\n",
    "`input_label` key, and a `properties` key, which work in the same way as for\n",
    "nodes.\n",
    "\n",
    "Relationships also have a `represented_as` key, which in this case can be\n",
    "either `node` or `edge`. The `node` option is used to \"reify\" the relationship\n",
    "in order to be able to connect it to other nodes in the graph. In addition to\n",
    "the configuration of nodes, relationships also have fields for the `source` and\n",
    "`target` node types, which refer to the ontological classes of the respective\n",
    "nodes, and are currently optional.\n",
    "\n",
    "To add protein-protein interactions to our graph, we can modify the schema configuration above to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "protein:\n",
      "    represented_as: node\n",
      "    preferred_id:\n",
      "    - uniprot\n",
      "    - entrez\n",
      "    input_label:\n",
      "    - uniprot_protein\n",
      "    - entrez_protein\n",
      "    properties:\n",
      "        sequence: str\n",
      "        description: str\n",
      "        taxon: str\n",
      "        mass: int\n",
      "protein isoform:\n",
      "    is_a: protein\n",
      "    inherit_properties: true\n",
      "    represented_as: node\n",
      "    preferred_id: uniprot\n",
      "    input_label: uniprot_isoform\n",
      "protein protein interaction:\n",
      "    is_a: pairwise molecular interaction\n",
      "    represented_as: edge\n",
      "    preferred_id: intact\n",
      "    input_label: interacts_with\n",
      "    properties:\n",
      "        method: str\n",
      "        source: str\n",
      "\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "print_yaml(join(schema_path, '06_schema_config_pandas.yaml'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have added `protein protein interaction` as an edge, we have to simulate some interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import InteractionGenerator\n",
    "\n",
    "# Simulate edges for proteins we defined above\n",
    "ppi = InteractionGenerator(\n",
    "    interactors=[p.get_id() for p in proteins],\n",
    "    interaction_probability=0.05,\n",
    ").generate_interactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U5Z5S0 interacts_with R9B8P2'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naturally interactions/edges contain information about the interacting source and target nodes\n",
    "# let's look at the first one in the list\n",
    "interaction = ppi[0]\n",
    "f\"{interaction.get_source_id()} {interaction.label} {interaction.get_target_id()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'signor'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarly to nodes, it also has a dictionary of properties\n",
    "interaction.get_properties()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with nodes, we add first createa a new BioCypher instance, and then populate it with nodes as well as edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BioCypher(\n",
    "    biocypher_config_path=join(schema_path, '06_biocypher_config.yaml'),\n",
    "    schema_config_path=join(schema_path, '06_schema_config_pandas.yaml'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -- Loading ontologies...\n",
      "INFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n"
     ]
    }
   ],
   "source": [
    "# Extract id, source, target, label, and property dictionary\n",
    "def edge_generator(ppi):\n",
    "    for interaction in ppi:\n",
    "        yield (\n",
    "            interaction.get_id(),\n",
    "            interaction.get_source_id(),\n",
    "            interaction.get_target_id(),\n",
    "            interaction.get_label(),\n",
    "            interaction.get_properties(),\n",
    "        )\n",
    "\n",
    "bc.add(node_generator(proteins))\n",
    "bc.add(edge_generator(ppi))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the interaction DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relationship_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>relationship_label</th>\n",
       "      <th>source</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intact867611</td>\n",
       "      <td>U5Z5S0</td>\n",
       "      <td>R9B8P2</td>\n",
       "      <td>protein protein interaction</td>\n",
       "      <td>signor</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>H0D1M0</td>\n",
       "      <td>U5Z5S0</td>\n",
       "      <td>protein protein interaction</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>H0D1M0</td>\n",
       "      <td>X8N1C4</td>\n",
       "      <td>protein protein interaction</td>\n",
       "      <td>intact</td>\n",
       "      <td>x f i d j l n r u n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>H0D1M0</td>\n",
       "      <td>R9B8P2</td>\n",
       "      <td>protein protein interaction</td>\n",
       "      <td>None</td>\n",
       "      <td>y j m c u r l c x p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>X8N1C4</td>\n",
       "      <td>103919</td>\n",
       "      <td>protein protein interaction</td>\n",
       "      <td>intact</td>\n",
       "      <td>v w c m l a t q v g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>X8N1C4</td>\n",
       "      <td>R9B8P2</td>\n",
       "      <td>protein protein interaction</td>\n",
       "      <td>intact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relationship_id source_id target_id           relationship_label  source   \n",
       "0    intact867611    U5Z5S0    R9B8P2  protein protein interaction  signor  \\\n",
       "1            None    H0D1M0    U5Z5S0  protein protein interaction    None   \n",
       "2            None    H0D1M0    X8N1C4  protein protein interaction  intact   \n",
       "3            None    H0D1M0    R9B8P2  protein protein interaction    None   \n",
       "4            None    X8N1C4    103919  protein protein interaction  intact   \n",
       "5            None    X8N1C4    R9B8P2  protein protein interaction  intact   \n",
       "\n",
       "                method  \n",
       "0                 None  \n",
       "1                 None  \n",
       "2  x f i d j l n r u n  \n",
       "3  y j m c u r l c x p  \n",
       "4  v w c m l a t q v g  \n",
       "5                 None  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.to_df()[\"protein protein interaction\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it is worth noting that BioCypher relies on ontologies, which are machine readable representations of domains of knowledge that we use to ground the contents of our knowledge graphs. While details about ontologies are out of scope for this tutorial, and are described in detail in the [BioCypher documentation](https://biocypher.org/tutorial-ontology.html), we can still have a glimpse at the ontology that we used implicitly in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing ontology structure based on https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl\n",
      "entity\n",
      "├── association\n",
      "│   └── gene to gene association\n",
      "│       └── pairwise gene to gene interaction\n",
      "│           └── pairwise molecular interaction\n",
      "│               └── protein protein interaction\n",
      "└── named thing\n",
      "    └── biological entity\n",
      "        └── polypeptide\n",
      "            └── protein\n",
      "                ├── entrez.protein\n",
      "                ├── protein isoform\n",
      "                └── uniprot.protein\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<treelib.tree.Tree at 0x11f7fe2c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.show_ontology_structure()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To keep or Remove"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "BioCypher provides feedback about property conflicts; try running the code\n",
    "for this example (`04__properties.py`) with the schema configuration of the\n",
    "previous section (`03_schema_config.yaml`) and see what happens.\n",
    "</div>\n",
    "\n",
    "@slobentanzer - nothing drastic happens haha (I guess it's expected that we don't have mass? :D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'PLWSVAKIHAEELPLLEYFVPDGSYDVPRGKMVNEFSEPEHWNVQCRADMYPEESIGKKYDILQMNDCMQTAFPAPIHQRCIEQHSEKKPMGLRGECFSHYMYEGTYKDIIPWQCGYDKHTLVIDIVGPGCRYTFFPWTSNFRRMGKLRKVLLPVNIKPYQRSWYNMVYDTAWGDVHGYDFIYPIWYNAMCAIDSNVYIGTHLFIMFEHMMAMKYIKRFCFLKEWFPHSLCKTKPKKDNDRNIQASVV',\n",
       " 'description': 'y n d f b v j i d t',\n",
       " 'taxon': '8076'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proteins[0].get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -- Loading ontologies...\n",
      "INFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'uniprot.protein':   node_id       node_label                                           sequence   \n",
       " 0  R5E6J1  uniprot.protein  WTSNHIYTVPYHFLHHYVFFFKFQICIKFMIFLVPGYPHQEWLYCD...  \\\n",
       " 1  J2N1M0  uniprot.protein  WHDEHQTWEFVSMGAAYPCRFSENVGYFCAIAIIDDLRQHRCCTSW...   \n",
       " 2  U8K1R6  uniprot.protein  DTASYNTMAGYFWQHRKDPNSRIFSCKLIARSVYQHFALTMYMDPM...   \n",
       " \n",
       "            description taxon  mass      id preferred_id  \n",
       " 0  p k q i g q r u x t   964  2163  R5E6J1      uniprot  \n",
       " 1  u b r e v i i c j q  4258  9531  J2N1M0      uniprot  \n",
       " 2  o f c m z a n y y p   328  7519  U8K1R6      uniprot  ,\n",
       " 'entrez.protein':   node_id      node_label                                           sequence   \n",
       " 0  573426  entrez.protein  NKKADRWISWHQYPRPHIHEIFKFQMHHQLATEYFTWEVLHHMPGL...  \\\n",
       " 1  865711  entrez.protein  VDMPKRFVFRHDEGWMPANWRPFVPLYMESSYPVRYCTKGPRAEMY...   \n",
       " 2  639349  entrez.protein  HHPTSLRHFTFYSNQFYTFWHEGFTEEKEDQKGFYLKSGRATKYSW...   \n",
       " \n",
       "            description taxon      id preferred_id  \n",
       " 0  t s q p e q e w e g  9606  573426       entrez  \n",
       " 1  x h s y z w r y k x  9606  865711       entrez  \n",
       " 2  s z c g x b d g k a  9606  639349       entrez  }"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of proteins to be imported (now with properties)\n",
    "proteins = [\n",
    "    p for sublist in zip(\n",
    "        [RandomPropertyProtein() for _ in range(n_proteins)],\n",
    "        [EntrezProtein() for _ in range(n_proteins)],\n",
    "    ) for p in sublist\n",
    "]\n",
    "# New instance, populated, and to DataFrame\n",
    "bc = BioCypher(\n",
    "    biocypher_config_path=join(schema_path, '04_biocypher_config.yaml'),\n",
    "    schema_config_path=join(schema_path, '03_schema_config.yaml'),\n",
    ")\n",
    "bc.add(node_generator(proteins))\n",
    "bc.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biocypher-Ca5VQ1YT-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ff371c403bc11abbc3c8e1391dba3b01886d66becfc523eea8e3dc677d5b98e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
